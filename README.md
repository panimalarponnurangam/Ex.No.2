
# Ex.No: 2 	Evaluation of Prompting Tools Across Diverse AI Platforms: ChatGPT, Claude, Bard, Cohere Command, and Meta 
### DATE:                                                                            
### REGISTER NUMBER : 212222110031
### NAME : PANIMALAR P
 
### Aim:
To compare the performance, user experience, and response quality of different AI platforms (ChatGPT, Claude, Bard, Cohere Command, and Meta) within a specific use case, such as summarizing text or answering technical questions. Generate a Prompt based output using different Prompting.
### AI Tools required:
- ChatGPT (GPT-4) ->	chat.openai.com
- Claude	claude.ai -> (Anthropic)
- Bard (Gemini) ->	bard.google.com
- Cohere Command R+ ->	cohere.com API access
- Meta LLaMA ->	Open-source via HuggingFace or local deployment

# Methodology
## Platforms Tested: 
ChatGPT (OpenAI GPT-4), Claude (Anthropic), Bard (Google Gemini), Cohere Command R+, Meta LLaMA (through open-source deployment or third-party interfaces).

## Prompt Types:
Informative, Creative, Logical Reasoning, Instruction-following, and Conversational.

## Evaluation Metrics:
- Relevance (How closely the output matches the prompt)
- Accuracy (Correctness of information)
- Creativity (Novelty in responses)
- Conciseness (Clear and brief)
- Tone & Coherence (Natural language quality)

## Procedure:
1.Standardized prompts were created across 5 types.
2.Each was entered into all 5 AI platforms.
3.Responses were collected and evaluated by 3 human reviewers using a 1–5 rating scale for each metric.
4.Averages were calculated and compared across models.

# Prompt Types Explained:

## 1. Informative Prompt
**Prompt:** “Explain Quantum Computing in simple terms.”

**ChatGPT:** Clear analogy-based explanation using real-world comparisons.

**Claude:** Similar clarity but slightly more verbose.

**Bard:** Balanced technical depth and simplicity.

**Cohere Command:** Less engaging, but accurate.

**Meta LLaMA:** Technical, but less user-friendly.

## 2. Creative Prompt
**Prompt:** “Write a poem about time as a river.”

**ChatGPT:** Vivid imagery, metaphor-rich.

**Claude:** Philosophical tone with narrative flow.

**Bard:** Elegant but slightly mechanical.

**Cohere Command:** Limited creativity.

**Meta LLaMA:** Abstract, inconsistent rhyme.

## 3. Logical Reasoning Prompt
**Prompt:** “If all cats are mammals and some mammals are not cats, is it true that all mammals are cats?”

**ChatGPT:** Clear logical reasoning, correct.

**Claude:** Correct with step-by-step reasoning.

**Bard:** Accurate but less detailed.

**Cohere Command:** Confused logic.

**Meta LLaMA:** Inconsistent logic.

## 4. Instruction-following Prompt
**Prompt:** “List 3 benefits of solar energy in bullet points.”

**ChatGPT:** Follows instruction perfectly.

**Claude:** Follows well with extra explanation.

**Bard:** Sometimes adds more than 3.

**Cohere Command:** Sometimes misses bullet formatting.

**Meta LLaMA:** May skip structure or add extras.

## 5. Conversational Prompt
**Prompt:** “I’m feeling nervous before an exam. Can you help?”

**ChatGPT:** Empathetic, practical advice.

**Claude:** Gentle and supportive.

**Bard:** Informative but less emotional.

**Cohere Command:** Robotic tone.

**Meta LLaMA:** Not emotionally aligned.

## 7.Code Generation Prompt (New)
**Prompt:** “Write a Python function to check if a string is a palindrome.”

**ChatGPT:** Correct, well-commented code

**Claude:** Accurate with explanations

**Bard:** Clean code, minimal comments

**Cohere:** Works but no explanation

**Meta:** Often incomplete or syntax errors

# Summary:

**ChatGPT (GPT-4)** - leads in versatility, structure, and creativity.

**Claude** - is excellent for empathy and deep reasoning.

**Bard (Gemini)** - offers concise and technically accurate results but lacks consistency.

**Cohere** - Command is good for factual tasks but not ideal for creative or emotional prompts.

**Meta LLaMA** - is best used by developers with customization needs but not yet consumer-ready in natural conversation.

 # Result : 
Thus, the evaluation of prompting tools across leading AI platforms- ChatGpt , Claude , Bard , Cohere Command, and Meta’s based models has been analysed.
